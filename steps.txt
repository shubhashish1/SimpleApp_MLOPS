1. Create an environment named wineq and acitvate that conda environment.
2. Create requirements.txt file with following requirements listed:
     .dvc
     .dvc[gdrive]
     .scikit-learn
     . pandas
    Now install the requirements by command pip install -r requirements.txt
3. Now let's create a README.md file and put all steps in that.
4. Now let's create a template file to create the project folder structure with name template.py
5. Put the templates code which are nothing but the dirs and files we want to create and run by command : python template.py
6. Create a folder named data_given where we will keep our data and also it can be used as our remote data repo.
7. put the winequality.csv file there.
8. Now initialize git and dvc and also push the data to dvc:
     .git init
     .dvc init
     .dvc add data_given/winequality.csv
     .git add .
     .git commit -m "first commit"
     .git branch -M main
     .git remote add origin https://github.com/shubhashish1/SimpleApp_MLOPS.git
     .git push -u origin main

     â€¦or push an existing repository from the command line
git remote add origin https://github.com/shubhashish1/SimpleApp_MLOPS.git
git branch -M main
git push -u origin main

9. Then we have to put all the necessary params in the params.yaml
10. Now let's create our first file in src to get the data in the name get_data.py
11. Read the params.yaml file via this file and try to fetch the data source dynamically and create a dataframe.
12. Now let's create a file to load that data from get_data.py put it in the data/raw through file load_data.py
13. Create a method to store the raw data in the raw folder in the load_data.py file.
14. Now we have to specify all the stages that are needed to be performed for the project to run in the dvc.yaml
15. Let's update this load_data to raw folder as first stage in dvc.yaml
        stages:
            load_data:
                cmd: python src/load_data.py --config=params.yaml
                deps:
                -src/get_data.py
                -src/load_data.py
                -data_given/winequality.csv
                outs:
                -data/raw/winequality.csv
16. Now we can run the dvc.yaml by command dvc repro and this will create a dvc.lock file.
17. This dvc.lock file keeps the track of every changes done in individual stages.
18. Create a method to store the raw data in the raw folder in the split_data.py file.
19. Now we have to specify all the stages that are needed to be performed for the project to run in the dvc.yaml
20. Let's update this load_data to raw folder as first stage in dvc.yaml
        split_data:
            cmd: python src/split_data.py --config=params.yaml
            deps:
            - src/split_data.py
            - data/raw/winequality.csv
            outs:
            - data/processed/train_winequality.csv
            - data/processed/test_winequality.csv
21. Now we can run the dvc.yaml by command dvc repro and this will create a dvc.lock file.
22. This dvc.lock file keeps the track of every changes done in individual stages as it runs and skips the load_data stage and then runs the split_data stage.
23. Create a method to store the raw data in the raw folder in the train_and_evaluate.py file.
19. Now we have to specify all the stages that are needed to be performed for the project to run in the dvc.yaml
20. Let's update this load_data to raw folder as first stage in dvc.yaml
        train_and_evaluate:
            cmd: python src/train_and_evaluate.py --config=params.yaml
            deps:
            - data/processed/train_winequality.csv
            - data/processed/test_winequality.csv 
            - src/train_and_evaluate.py
            params:
            - estimators.ElasticNet.params.alpha
            - estimators.ElasticNet.params.l1_ratio
            metrics:
            - report/scores.json:
                cache: false
            - report/params.json:
                cache: false
            outs:
            - saved_models/model.joblib
21. Now we can run the dvc.yaml by command dvc repro and this will create a dvc.lock file.
22. This dvc.lock file keeps the track of every changes done in individual stages as it runs and skips the load_data,split_data stage and then runs the train_and_evaluate stage.
23. Here we are also making params.json and socres.json in report folder to track the params and metrics changes.
24. We can check the dvc metrics or scores by command: dvc metrics show

o/p: 

Path                alpha    l1_ratio    mae      r2       rmse
report\scores.json  -        -           0.65515  0.01301  0.80312
report\params.json  0.9      0.4         -        -        -


25. We can track the difference of metrics between old and new if we have retrained the model with modification
    with command: dvc metrics diff